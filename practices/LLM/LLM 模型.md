## LLM 模型

### ChatGLM

:sailboat:引入：客服聊天机器人

预训练：在预训练阶段，Chat GLM使用了大规模的文本数据，这些数据可能包括书籍、文章、网页内容等，目的是让 **模型学习到通用的语言表示**

正式训练：

* **任务描述**：假设我们需要构建一个客服聊天机器人，它能够理解用户的问题并提供准确、友好的回答。
* **数据集准备**：为了进行正式训练，我们会准备一个包含客户对话的数据集。这个数据集应该包含用户的问题和客服的相应回答。
* **微调目标**：在这个阶段，我们的目的是让ChatGLM学习如何生成适合客服场景的对话，包括理解用户查询的意图、提供有用的信息、以及保持礼貌和专业的沟通风格。
* **训练过程**：
  * **数据预处理**：清洗和预处理数据，确保对话数据的质量和一致性。
  * **模型微调**：使用客服对话数据集对预训练好的 ChatGLM 进行微调。微调过程中，模型会学习特定于客服场景的语言模式。
  * **评估和迭代**：在微调过程中，定期评估模型的性能，使用诸如 BLEU、ROUGE 或人类评估等指标来衡量生成的对话质量。根据评估结果对模型进行调整。
* **总结**：在正式训练时，选择哪些数据集取决于具体的应用场景和目标。例如，如果目标是创建一个客服聊天机器人，那么应该选择包含客服对话的数据集，如Customer Service Dialogs。如果目标是为特定行业创建聊天机器人，则可能需要结合通用对话数据集和行业特定的自定义数据集。





