## Social-RAG

### Abstract:

许多AI agent被用来在人类群体合作或在线讨论中提出建议，比如在群聊中推荐信息或帮助决策。

:sailboat:问题是：这些AI可能会提供不符合群体喜好的建议，或者在社交上显得不合时宜、不恰当，这回让人觉得AI令人烦恼或无用。例如，如果AI在某个时机发布了一条不相关或尴尬的消息，可能会影响群体的互动氛围。

在群体互动的场景中，有丰富的“社交历史”和“社交反馈”，这些信息可以用来帮助AI更好地理解和融入群体的习惯和偏好。简单说，群体的过往互动记录中有许多线索（如人们对某些话题的反应、不同对象之间的用语方式等），可以用来调整AI的行为，让其更符合群体的期望。

:ocean:Social-RAG

提出的一种方法，目的是将AI代理的行为“扎根”于群体的社交信息中，使其更贴近群体的习惯和需求。具体的工作流程如下：

1. 检索：首先==从某个群体过往的社交互动中==“检索”相关信息，找到==与当前情景最贴切的==历史记录或行为习惯。
2. 选择：接着，从检索到的信息中挑选出有用的“社交信号”，这些信号可以是人们偏好的话题、语气等，这样可以确保信息与群体氛围一致。
3. 生成：然后将上下文输入到一个大型语言模型中，以生成给该群体的消息。

:racing_car:实际应用 - PaperPing系统

用Social-RAG实现了一个叫“PaperPing”的系统。这个系统会在群聊中推荐学术论文。它通过之前的用户研究，收集了39名研究者的反馈，确定了如何使用“社交信号”来调整推荐行为。

PaperPing的部署结果显示，它可以在群组中发布相关且不会打扰群体的推荐，成功融入群体的社交互动中。这表明它对AI在群体环境中的适应能力是有帮助的。在为期三个月、覆盖18个群聊频道的测试中，研究发现，PaperPing能够有效地发布相关性较高的信息，并且不会破坏群体已有的社交习惯。相反，它还能帮助群体建立“共同的认知基础”（common ground），即大家在某个话题上形成共同理解的机会。

### Introduction

:ice_cream:proactive agents   and     reactive agents

* reactive agents：仅在接收到明确的人类指令之后行动，例如你明确告诉一个助手去执行某个任务
* proactive agents：则不同，它们可以在没有收到明确请求的情况下主动采取行动。这样的AI代理可能提供额外的信息或建议，有助于激发更广泛的讨论或提高群体互动。例如，某些AI可以主动调整会议布局，或在头脑风暴中提供灵感。

:pager:proactive agents 主动型代理的潜力和机会

主动型AI代理相比反应型，有潜力为群体提供未明确请求的有用信息，激发新的想法，促进更多元的参与。举例来说：

* **CoExplorer系统**会根据会议的阶段和目标调整窗口布局，从而帮助保持会议的专注度并减少工作量。
* 另一项研究发现，AI代理主动在头脑风暴中插入文本提示，能激发新的讨论方向。这说明主动型AI有助于增强互动性和创造力。

潜在问题和挑战：虽然有潜力，但主动型AI也可能带来麻烦或让人反感。没有明确的用户指令可能导致AI行为的模糊性，出现不相关或不合时宜的插入，打扰正常交流。例如：

* 如果AI在不合适的时间插入消息，可能让用户感到困扰或分心。

* 甚至在人类扮演AI角色的“巫师实验”（wizard-of-oz study）中，接近一半的AI插入被群体成员忽视或否定，因为内容不相关或时间点不合适。

:pakistan:social中的机遇

尽管存在挑战，社交环境中的丰富人际互动和人与AI之间的交互也提供了独特的学习和适应机会。一个成功的AI agent可以利用这些互动，逐步调整自己的行为模式，满足用户的偏好：

* 它们可以根据社交空间中的过去和当前互动情况来确定合适的信息、语调和时间点来介入群体讨论。
* 例如，AI可以用符合群体社交规范的风格与群体成员交流，并在适当的时间进行互动，而不会打断现有的互动氛围。

:uganda:AI model的灵活性和挑战

* 大语言模型（如你使用的ChatGPT）具备生成类人文本的能力，使得AI代理能够生成更灵活的对话和信息，而不只是机械式的预设回应。
* 然而，目前仍存在一个挑战：如何让这些模型在没有频繁明确指令的情况下，生成符合群体偏好和规范的消息。这需要在设计和技术上进一步思考和优化。

##### 工作内容强调

目的是：如何让 proactive agents 在群体的社交空间内更好地融入、适应和符合群体的兴趣和社交规范。文本提出的Social-RAG流程利用群体内的“社交信号”，即从==过去的群体互动==和==成员与AI的交流==中获取上下文信息，使AI生成的内容更符合群体的需求和偏好。

:kiwi_fruit:传统的RAG是从知识库中获取事实作为上下文，来提升语言模型生成的内容的准确性和真实性。而Social- RAG有所不同，它从群体的社交数据源中检索信息，如群聊记录，以提升语言模型在社交环境中的适应能力。

:yum:“PaperPing”系统

1. 为了验证Social- RAG的实际应用，研究者开发了一个名为PaperPing的系统。它会主动在<u>研究群体</u>的聊天空间中推荐**学术论文**。
2. 选择==学术群聊空间==作为测试场景是因为学术讨论本身具有很强的协作性，研究人员经常需要交流，而日益增加的学术文献数量也使得对相关论文的识别变得愈加重要。
3. 在两次研究中，39名研究者的反馈表明，他们经常在群聊中根据具体成员的需求推荐论文，并利用表情符号和回复来进行反馈。PaperPing设计时正是借鉴了这种已有的社交行为，使其更贴近实际需求。

:sagittarius:研究成果和观察

* PaperPing的表现证明了它能以最小的用户输入，学习到研究者个体和群体的偏好，并利用群体内现有的反馈信号（如链接分享和表情反应）不断适应。
* PaperPing生成的消息被认为具有较高的上下文相关性
* 此外，系统能够无缝融入现有群体实践，而不会打乱群体的动态，并在群体内促进“共同认知”。

### Methodology

:kazakhstan:工作目标概述：设计了一种可以在群体社交空间中主动发布信息的AI agent，使其既能提供帮助又能符合群体的社交动态。

大语言模型（LLMs）尽管能生成类人文本，但在群体的社交环境中，它们缺乏对社交上下文的具体理解。因此，**Social-RAG**旨在借鉴传统的RAG流程，将AI代理的生成与群体的社交信息结合起来，使其更好地匹配群体的兴趣和规范。

:label:设计目标（design goals）

##### **DG1**：在群体社交上下文中给出建议。

AI的建议需要与群体的背景和兴趣相关，并通过解释其与群体的关联来增强信任。类似于RAG方法通过引用知识库内容提升可信度，Social-RAG希望通过社交上下文使AI建议更加可信和贴合群体需求。

##### **DG2**：融入群体而不打扰已有社交实践。

AI应与群体的交流无缝融合，不应打扰或削弱人际互动。过于频繁或冗长的信息可能导致用户厌烦，甚至降低群体的参与度。

##### **DG3**：降低用户在偏好设置上的初始投入，并允许持续改进。

传统AI通常需要用户明确输入偏好，增加使用门槛。Social-RAG希望利用群体现有的活动痕迹来推测用户偏好，并通过现有的社交反馈机制，如表情和回复，实现持续学习。

##### 建立群体“共同认知”（common ground）

AI的互动应在公开的群体空间中进行，使得反馈和调整过程透明化，从而增强群体成员之间的理解和信任。

:golf:Social-RAG 工作流程

* 步骤一：收集并索引群体交互内容，创建社交知识库（每个群聊都有这样的知识库）

  通过收集群体的历史互动信息（如消息内容、情绪和反应等），AI可以学习并存储关于群体成员偏好的“社交事实”。

* 步骤二：从知识库中检索社交信号，为AI生成的解释提供背景。

  当AI需要提出建议时，可以引用相关的群组历史信息、元数据和相关成员，以此增强其建议的相关性和可信度。

* 步骤三：排序社交信号并生成简洁的消息

  使用大语言模型生成与群体对话风格一致的自然语言信息，确保信息简洁明了，不打扰群体的正常交流。

* 步骤四：在社交频道中关注generation的信息，并收集和索引群体反应。

  通过收集群体对AI信息的反馈，如表情和回复等，进一步学习和适应用户偏好。这样不仅增强了AI的适应性，也提升了用户与AI之间的互动效果。