## Tool Learning with Foundation Models(https://arxiv.org/abs/2304.08354)

“工具学习”（tool learning）与基础模型（foundation models）结合的潜力

* 引言背景：强大的基础模型可以通过“工具学习”来增强人工智能系统的能力。这种能力的增强使得AI可以在解决问题的过程中更准确、高效、自动化。
* 工具学习的范式：“tool leaning” 利用基础模型的能力与特定工具的结合。基础模型通常指的是那些经过大规模训练、能够适用于多种任务的模型（如大语言模型） 。这里的“工具”则可能包括专用软件、插件或任务工具。==工具与模型的互补性可以让模型在更广泛的场景中表现更出色==。
* 文章阐述了一般的工具学习框架，包括：理解用户指令、分解复杂任务、动态调整任务计划、并选用合适工具来解决各个子任务。目的是提升模型在工具使用中的能力与泛化性。
* 实验与开发问题：实验中使用了18种代表性工具，展示了当前基础模型在“工具化”学习上的潜力。同时，论文也指出了若干需要进一步研究的开放问题，例如工具使用的安全性和可信性、基础模型如何参与工具创造、以及如何解决个性化问题等

### Introduction

工具与基础模型结合的背景与研究框架

1. 工具的重要性：工具作为人类能力的延伸，大大提升了生产力、解决问题的效率，并且塑造了我们的社会和文化实践。这些历史背景强调了工具对人类智慧的深刻影响。
2. AI与工具使用：随着AI的发展，自然而然会产生一个问题：AI能否像人类一样灵活地使用工具？要实现这一点，AI需要具备对工具功能的深入理解、用户意图的解析能力，以及合理规划与推理能力。这个部分指出了AI在工具使用上的主要难题，比如传统模型无法有效掌握复杂的工具操作，而基础模型的出现改变了这一局面。
3. 基础模型的能力：现代的基础模型，比如大规模的NLP模型和多模态模型，展示了更强的语义理解、推理和复杂交互能力。==这些模型通过大规模预训练积累了广泛的世界知识，使得它们可以在更广泛的场景中进行工具化操作==。
4. 工具与基础模型的结合：工具和基础模型的结合被称为“工具学习”，这是一种结合专业工具和基础模型的范式，目的是提升解决问题的准确性、效率和自主性。尽管已有的研究展示了基础模型在特定任务中的工具化能力，但还存在理解不足的问题。文献提出，系统地审视当前的进展、挑战和未来方向是非常必要的。
5. 文献综述与框架构建：首先介绍工具与基础模型的交互历史与背景。然后，文章提出了一个通用的工具学习框架，涵盖控制器（通常是基础模型）、工具集、环境、感知器和用户等元素。整个学习过程从用户指令开始，模型需制定可执行的计划并动态调整子任务。关于训练策略，文中提到了主流方法，如从示例中学习和通过反馈学习。

### background

1. 人类工具使用的认知起源
   * 工具作为人类能力的延伸：工具从远古时代起就一直是人类进化的重要组成部分，被视为人类能力的外在延伸。相比于其他物种，人类的工具使用表现出更高的复杂性。
   * 工具使用的智力水平分级：研究者将人类工具使用的智力水平分为三种模式：“辅助工具使用”、“任意工具使用”和“自由工具使用”。这种分级说明了工具使用的不同层次，从被动的、非意识的工具使用（如避雨），到复杂的自由工具使用（如选择和操作工具做新任务）。自由工具使用被认为需要更高的技术推理能力，可以通过观察和模仿他人来学习新动作。
   * **从物理工具到概念工具的过渡**：人类的工具不仅限于物理世界，还包括认知工具，例如帮助高级思维的辅助工具。它们能支持复杂的思维过程、降低认知负荷、帮助测试假设等。这样的工具在现代教育和科研中尤为重要，体现了工具的多样性。
2. 工具分类：用户界面视角
   * **物理交互工具**：这些工具涉及与物理世界的直接交互，如机器人、传感器、可穿戴设备等。它们可以感知和响应用户的物理环境，广泛用于制造、医疗、教育等领域。虽然主要与物理世界交互，但输入可能通过图形用户界面或代码层面生成。
   * **基于图形用户界面的工具（GUI-based Tools）**：这类工具通过视觉交互（如按钮、菜单等）来简化复杂任务，是许多软件应用的核心。例如，浏览器、微软Office、Photoshop等。它们的优势在于简化工作流程，降低学习门槛，但在某些需要灵活控制的场景可能表现不足。
   * **基于程序的工具（Program-based Tools）**：这些工具通过编程接口进行交互，提供了高度的灵活性和可定制性。例如，SDK、编程库等。这类工具适用于技术用户，但学习曲线较陡，需要较高的编程技能。尽管对人类来说难度较大，但对基础模型可能并没有同样的挑战。
3. 基础模型的范式转变
   * **从分离任务到统一任务处理的演变**：在基础模型（Pre-trained Language Models, PLMs）出现之前，自然语言处理（NLP）需要针对不同任务设计专门的模型和目标，例如依存句法分析、命名实体识别和文本摘要等。这种割裂式的处理方式限制了对语言的整体理解能力。==PLMs通过大规模语料库的训练，学习了广泛的语言知识和世界知识，开创了“预训练-微调”的新范式，使得不同任务能从相同的起点开始，只在特定任务适应过程中有所分化。==这样的模式极大地提升了NLP的表现。
   * **基于Transformer的PLM能力提升**：PLM的成功基于Transformer架构，通过大规模预训练，它们获得了出色的语义理解、推理和生成能力。这种以提示（prompts）为核心的交互方式证明了PLM的灵活性和广泛的泛化能力。
   * 超越语言的复杂任务：尽管基础模型在语言任务上取得了巨大突破，但仍存在许多超出纯语言范围的任务。例如，生成演示文稿、构建3D模型或安排会议等复杂任务==需要通过工具学习和自然语言结合的方式来解决==。基础模型作为“翻译者”，将复杂任务分解为可执行的子任务，并生成特定工具理解的指令，从而使得这些任务对普通用户更易访问。
   * **工具学习的潜力和挑战**：通过自然语言的接口，工具学习在自动化客户服务、个人助理、自动驾驶等领域展示了广泛的应用前景。然而，针对非语言任务的挑战依然存在，需要==进一步挖掘如何利用自然语言和工具学习的结合来解决复杂问题。==
4. 工具与基础模型的互补角色
   * **工具的优势**：
     1. 基础模型在记忆能力上表现出色，但无法记住所有训练数据，也难以实时更新知识。通过结合实时工具（如搜索引擎、数据库等），模型可以缓解这种记忆负担，避免生成不真实的内容。
     2. 专用工具在特定领域具有独特的功能，能够满足更复杂的需求，例如科学计算中使用Wolfram工具。基础模型可以调用这些工具，以实现更广泛的任务覆盖。
     3. 基础模型常因决策过程不透明而受批评，而工具的执行过程可以清晰展示任务的解决步骤，提高了模型的可解释性和透明度。
   * 基础模型的优势：
     1. 基础模型能够处理大量数据，具备强大的推理和决策能力，这在需要因果推理的复杂任务中尤为重要。
     2. 基础模型可以理解用户意图，简化复杂任务的交互，提供个性化和精确的响应，使得非技术用户也能够快速掌握复杂工具。

### tool learning

:sailboat:components of tool learning

* 工具集：工具集是工具学习的基础，包含一组具有不同功能的工具。通常，我们使用API（应用程序接口）作为示例，API可以接收模型的输出作为输入。例如，天气API的输入可能是地点和时间，输出则包含温度或风速等信息。工具的形式和功能多样，使用API示例可以较好地说明工具与模型的交互。
* 环境：环境是工具操作的场所，提供了工具执行的反馈。环境可以是虚拟的（如模拟环境）或真实的。虚拟环境具有易访问、可重复等优势，但可能不能完全模拟现实的复杂性；而真实环境更具挑战性，但能提供更真实的反馈。
* 控制器：控制器通常由基础模型担任，是工具学习框架的“大脑”，负责制定任务执行的计划。它需要理解用户意图并与工具集建立关联，选择合适的工具完成任务。在面对复杂查询时，控制器需要将任务分解为多个子任务，依赖模型的强大规划和推理能力。🧠
* 感知器：感知器处理用户和环境的反馈，并生成供控制器使用的总结反馈。简单的反馈处理可以是连接用户和环境反馈，而更复杂的场景下感知器需支持多模态（如文本、视觉、音频）以捕获不同类型的反馈。

:pager:General Procedure of Tool Learning

* **意图与工具的理解**：控制器需要首先理解用户的意图（intent），这涉及将自然语言查询转化为高层次任务。同时，还需==理解工具集的功能和目标，从而在用户意图与工具之间搭建桥梁==。首先，控制器需要理解用户的意图，这涉及将自然语言表达的需求转化为高层次任务。同时，控制器需要掌握工具集合中每个工具的功能和目标，以便建立用户需求与工具功能之间的联系。

* **规划与推理**：一旦理解了用户意图和工具功能，控制器需要进行任务分解和规划，可能将一个复杂任务分解为多个子任务，制定执行顺序。这一步需要强大的推理能力，通过内省式推理（基于模型自身的规划）和外展式推理（依赖环境反馈调整计划），控制器能够逐步解决子任务。
* **与工具交互执行任务**：控制器选择合适的工具，生成并执行相应的操作计划。在这一过程中，环境和用户的反馈会传递给感知器，帮助控制器判断计划的有效性并进行必要调整。
* **反馈整合与学习改进**：通过不断观察环境和用户反馈，控制器逐步优化和完善其执行策略，确保能够更好地完成任务。工具学习可以通过示范和反馈进行训练，从而提升模型对工具的使用能力，实现更通用的工具学习能力

:taxi:实际案例：LLM如何获得“tool learning”的技能

天气查询助手

1. 背景与需求

   一个LLM需要提供实时的天气信息，但由于其内部知识是静态的，并不能直接回答用户有关当前天气情况的问题。通过tool learning，我们可以让LLM调用一个天气查询API，以便获得实时天气数据，从而满足用户需求。

2. tool learning 实现过程

   * **预训练与API调用能力的嵌入：在模型的训练或微调阶段，可以通过示例教它如何识别何时需要调用API.**

     :label:通过“Tool Learning”来扩展模型的功能，不一定需要调整LLM内部参数

     **不需要微调的情况**

     * **通过提示工程（Prompt Engineering）实现**：通常，我们可以通过设计特殊的提示（prompts）来让模型生成特定格式的请求。例如，给定一个指令模板，模型只需要生成符合这个模板的输出，而不需要改变内部参数。这种方式相对简单且无需更改模型。
     * **借助外部工具和框架**：一些框架（如 `LangChain` 或 `OpenAI Functions`）允许模型与外部工具交互，这种方式通过结构化的外部指令和代理系统处理模型输出，无需对模型本身进行微调。（配合上述的“提示词工程”使用）

     需要微调的情况

     * 如果模型需要更精准地理解何时调用工具，或者需要生成更复杂的请求格式（不同任务有对应复杂的请求格式），，可以对模型进行微调。这种微调通常涉及在现有数据上添加特定的“Tool Usage”任务数据，让模型学习如何更好地生成调用指令。
     * **使用强化学习（RL）优化调用策略**：在一些复杂场景中，模型可能需要通过试验和反馈优化调用策略，此时可以利用“强化学习”进行微调，但这通常是针对特定用例的需求。

   * **调用API的机制**

     当用户向模型提出问题，例如“今天北京的天气如何？”时，模型会首先判断这是一个需要实时数据的查询。

     > [!caution]
     >
     > 传统的语言模型本身并不能“主动”去调用API，因为它们只是生成文本的静态模型。它们并没有内置的执行能力。那么，“模型调用API”这个过程实际上是通过一种“环境”或“代理机制”来实现的，而模型本身则负责意图的判断(==这个query是否需要我去调用API==)和提供请求的生成(==需要的话，就生成特定格式的请求==) 即：判断何时调用工具以及如何调用工具的样本格式

     :sailboat:环境与中间件

     大多数情况下，模型被集成到一个更大的系统或“环境”中，这个系统可以执行模型生成的API请求。模型本身只负责生成==文本形式的API请求指令==，而由外部的代理系统解释并执行这些指令。

     * 例如，当用户向模型询问一个需要实时数据的问题时，模型通过提示或指令生成一个表示API调用的文本。外部的代理系统会识别出这条输出，并解析其意图，接着由代理实际执行API调用。

       ```json
       {
         "endpoint": "https://api.openweathermap.org/data/2.5/weather",
         "parameters": {
           "q": "Beijing",
           "appid": "your_api_key"
         }
       }
       ```

     * 外部环境解释模型的请求和执行API请求

       一个外部的“执行环境”会监控模型输出，识别并解析这种“API_REQUEST”形式的输出。然后，它会从文本形式的描述转化为实际的API调用请求。该环境使用合适的库（如 `requests` 在Python中）向指定的API发送请求，获取响应数据。

     * 反馈响应数据给模型

       将API返回的响应（通常是JSON或其他结构化数据）传递回模型，让模型将数据整合到其生成的自然语言回答中。假设API返回的响应是：

       ```Json
       {
         "weather": [{
           "description": "clear sky"
         }],
         "main": {
           "temp": 20.5
         },
         "wind": {
           "speed": 3.5
         }
       }
       ```

       LLM 解析这个JSON响应数据，提取出相关信息。然后模型根据提取的信息生成一个自然语言的回答，比如：“今天北京的天气是晴天，气温约为20.5°C，风速为3.5米/秒。”

### experiment

我们旨在探索工具学习的应用，并研究最先进的基础模型在利用工具方面的功效和局限性。我们选择了 18 种有代表性的工具进行评估，

1. **实验工具的选择与分类**：作者选择了18种具代表性的工具进行测试，涵盖了多种领域。工具被分为三大类：图形用户界面工具（GUI-based tools）、程序接口工具（API-based tools）和物理交互工具。这种划分有助于评估模型在不同交互模式下的表现。
2. 实验方法：
   * 使用了无工具（No Tool）、零样本（Zero-shot）和少样本（Few-shot）三种实验设置。无工具设置意味着模型仅依赖自身内部知识完成任务，而零样本和少样本设置则分别提供了工具使用说明和示例以帮助模型更好地理解任务和使用工具。
   * 实验评估的标准主要是工具调用的准确性与输出的合理性。如果模型在任务中正确调用了所有工具并且输出了合理结果，该任务被视为成功。

### result

1. **模型通过简单提示能够学会有效使用工具**：研究发现，在大多数情况下，模型只需要简单的提示就能有效利用工具，从而改善任务表现。这说明了基础模型具有相对快速适应工具使用的潜力。
2. **内在知识与工具使用的权衡**：当模型利用其内在知识（如搜索引擎和计算器）解决任务时，有时使用零样本提示（zero-shot prompting）结合工具可能会导致性能下降。这暗示了工具使用不当可能对结果有负面影响。然而，在少量示例提示（few-shot prompting）的情况下，结合工具始终能带来更好的效果，强调了合理使用工具的具体好处。
3. **模型之间的对比**：ChatGPT和text-davinci-003的表现差异揭示了一些重要问题。尽管ChatGPT经过了基于人类反馈的强化学习（RLHF）微调，它的表现不如text-davinci-003。原因可能是RLHF微调会削弱模型的特定任务能力和上下文学习能力；其次，ChatGPT的模型规模可能小于text-davinci-003，因此在处理复杂场景时表现更弱。
4. **工具表现差异**：不同工具的评估设置不同，使得直接比较具有挑战性。但在少量示例提示下，诸如地图、天气、幻灯片等工具表现出较高的完成率，而涉及更复杂操作的工具（如知识图谱、在线购物、3D模型构建）表现相对不足。这表明某些工具的使用模式无法通过少量示例轻松学会，特别是需要生成可执行代码作为API参数的工具，增加了使用难度。