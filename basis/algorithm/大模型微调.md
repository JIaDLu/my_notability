# 大模型改进

### 数据飞轮

1. 数据驱动决策

   首先，通过收集大量的数据，并进行深入分析，企业能够获得对市场、用户和业务的深刻洞察。这些洞察为决策制定提供了依据，使企业能够做出更加明智的决策。

   例如，一家零售企业通过分析销售数据和用户反馈，发现某一产品的销量下降，同时用户对该产品的质量和价格提出了一些意见。基于这些分析结果，企业决定对该产品进行改进，提高质量并调整价格。

2. 决策推动行动

   决策制定后，企业需要将其转化为实际行动。这些行动可以包括产品改进、营销策略调整、运营优化等方面。

   例如，企业根据决策结果，对产品进行了重新设计和生产，并推出了一系列促销活动。同时，企业还优化了供应链管理，提高了物流效率，以确保产品能够及时送达用户手中。

3. 行动产生数据

   行动执行后，会产生新的数据。这些数据可以用来评估行动的效果，并为下一轮的数据分析和决策制定提供依据。

   例如，企业推出新产品和促销活动后，可以通过销售数据、用户反馈等渠道收集新的数据，了解用户对新产品和促销活动的反应。这些数据可以帮助企业评估行动的效果，并为下一步的决策提供参考。

4. 数据反馈循环

   新产生的数据又会进入数据收集环节，开始新一轮的数据分析和决策制定。这样，数据飞轮就不断地循环运转，推动企业持续发展和创新。（**数据反馈：用户与模型的交互会产生新的数据，这些数据可以用来进一步优化模型，通过持续收集用户反馈和交互数据，模型可以不断学习和适应，提高其性能和准确性。**）

   例如，企业通过对新数据的分析，发现新产品和促销活动取得了良好的效果，但也存在一些问题。企业可以根据这些反馈，进一步优化产品和营销策略，不断提高业务绩效。

### 向量数据库 vectorDB

向量数据库(vactor database)是专门设计用来存储和检索<u>向量化数据</u>的数据库。

> 它的核心是通过向量来表示数据，比如文本、图像、音频等。通过LLM或DL模型，我们可以把复杂的数据（如句子、图片）转换成向量嵌入，即一个高维的数值向量。

向量数据库的主要功能就是管理和检索这些高维向量。

* **向量化过程**：对于文本，模型会将其转化为一个固定维度的向量，这个向量表示该文本的语义信息。对于图片、音频等数据类型，也可以使用深度学习模型生成相应的向量。
* **检索方式**：向量数据库中的检索不再是传统的精确匹配，而是通过**向量之间的相似度**（通常使用余弦相似度或欧几里得距离）来找到最相似的数据。比如，在文本检索中，用户输入一个查询句子，系统会将其转化为向量，然后在数据库中找到与这个向量最接近的若干文档的向量，返回这些文档作为结果。

##### 这里需要扩充一下为什么一个query能够被用一个vector来表示

query向量化这个过程往往是通过用一个预训练模型来实现的。例如：

有这样一个查询文本：

```python
“最好的手机是什么”
```

我们需要用一个预训练模型讲这句查询文本转换为一个向量。这里的预训练模型以BERT为例。

BERT的推理阶段，主要任务是根据训练中学到的语义表示，将输入的文本转化为一个包含丰富语义信息的向量。主要操作是：

* 输入处理：Tokenizer 编码

  BERT 不直接处理原始的自然语言文本。它会通过 **Tokenizer** 将文本转换为模型能够理解的数字格式。

  :label:文本分词: BERT 使用的是 WordPiece 分词技术，将输入文本切割成子词单元（subword units）

  ```python
  [CLS] 最 好 的 手 机 是 什 么 [SEP]
  ```

  `[CLS]`：表示分类任务或句子开头的标志，BERT 会用它来生成句子整体的表示。

  `[SEP]`：用来分隔句子，尤其是句对任务中的句子之间的分隔符。

  :label:**Token 转换为 ID**：每个分词后的 token 会被映射为一个唯一的整数 ID。例如，"最"、"好"、"的" 等每个 token 都会在词表中有对应的数字编号。

  :label:**生成其他嵌入向量**：BERT 还会为每个 token 生成对应的**位置向量**（Position Embeddings）等

* **输入经过 BERT 编码层（Transformer 层）**

  "最好的手机是什么？" 经过 BERT 的多层处理后，每个词（token）都会得到一个新的向量表示，这些表示包含了词的上下文关系和更丰富的语义。

* **[CLS] 位置的最终向量**

  > [!IMPORTANT]
  >
  > 推理过程中，BERT 通常会用**[CLS]** 位置的输出向量作为句子的整体表示。这个向量汇总了整个句子的信息，因此可以用它来表示查询的向量。【这个向量不仅包含了查询的基本语义，还融合了上下文关系，成为了该查询的最终语义表示。】

  推理过程中，BERT 通常会用**[CLS]** 位置的输出向量作为句子的整体表示。这个向量汇总了整个句子的信息，因此可以用它来表示查询的向量。

* 向量输出：查询向量化完成

至此，你可以简单理解，模型将句子“最好的手机是什么？”转化为一个向量，比如一个长度为 768 维的向量：
$$
v_{query}=[0.12,−0.45,0.88,...,0.33]
$$
这个向量代表了模型对该句子的**语义理解**.

2, 向量的相似度检索

这个查询向量被发送到**向量数据库**中。向量数据库中已经存储了一些与手机相关的文档或信息，每个文档也被预先转化为了向量（这些向量同样是由预训练模型生成的）。

例如，向量数据库中有以下几篇文档（每个文档有一个对应的向量）：

* **文档1**：介绍 iPhone 的优点，向量为 v1
* **文档2**：讨论三星手机，向量为 v2
* **文档3**：评价 Google Pixel，向量为 v3

这些文档的向量都存储在数据库中，可能有成千上万个文档，每个文档都是一个高维向量。

3, 相似度计算：

* **余弦相似度**：衡量两个向量之间的夹角，夹角越小（相似度越高），代表两个向量的语义越接近。
* **欧几里得距离**：计算两个向量之间的距离，距离越小，表示它们越相似。

4, 返回相关的文档

## 不需要train的LLM改进

这些技术的提出都基于 **LLM的预训练范式**，随着预训练模型越来越强大，研究者们开始探索如何在 **不重新训练** 的情况下，提升模型的任务性能。这些技术可以分为两大类：**基于提示词的优化** 和 **外部知识增强**。

### 基于提示词的优化

这是随着<u>预训练模型能力大幅提升</u>而提出的技术。由于模型的泛化能力很强，通过优化输入的提示词即可获得极好的结果。

#### Zero-shot Learning：

早期人们发现LLM能够在完全未见过的数据上生成合理的结果，这是早期任务中模型没有专门为某个任务训练也能生成结果的能力。

#### 提示词工程：

逐渐演变为设计更高效的提示词以引导模型实现更精确的任务效果。尤其是在 **GPT-3** 等大模型推出后。研究者发现，通过优化提示词的设计，能够让模型直接执行不同任务，而无需修改模型参数。

* ==链式思维chain of thoughts==：属于prompting engineering的一个重要分支，随着模型对复杂推理任务的需求提升，CoT技术应运而生。它帮助模型按步骤思考，解决推理能力不足的问题。这是在LLM需要处理多步推理任务时演变出来的。:sailboat:定义：在进行推理时，通过一系列中间推理步骤来达到最终结论的过程。对于复杂问题，简单的输入-输出模型往往不足以产生有效的结果，而是需要通过多个推理步骤，逐渐逼近最终的解决方案。

  :label:链式思维如何在大型语言模型中自然而然地出现

  当模型的规模足够大时，链式思维的能力开始自然涌现。这是因为：

  * **学习大量的文本数据**：大型语言模型训练时，接触了大量的文本数据，其中包含许多自然语言中的推理示例。通过训练，这些模型逐渐学会如何将信息连接起来，形成推理链。
  * **参数和结构的复杂性**：更大的模型拥有更多的参数和更复杂的结构，这使得模型能够捕捉到更深层次的逻辑关系和信息。

  :label:如何理解链式思维提示

  在提示中提供一些思维链示范作为范例。具体来说，我们探索语言模型在推理任务中执行少量提示的能力，给出由三元组组成的提示：<输入，思想链，输出>。思维链是导致最终输出的一系列中间自然语言推理步骤，我们将这种方法称为思维链提示。

  :american_samoa:优势

  1. 对于需要多个推理步骤的问题，链式思维使得模型在计算资源的分配上更加高效。具体来说：

     * **适应性计算**：模型可以根据问题的复杂度，**动态地分配计算资源**。对于需要更多推理步骤的问题，模型可以选择使用更多的计算能力来逐步解决每个子问题。

     * **优化资源利用**：通过识别哪些问题需要更深入的推理，模型能够将计算资源集中在最需要的地方，从而提高整体效率。这种方法在处理复杂推理任务时尤其有效，减少了不必要的计算开销。

  2. 只需将思维链序列的示例包含到少样本提示的示例中，就可以在足够大的现成语言模型中轻松引发思维链推理。

     :school_satchel:**少量示例提示**是一种有效的技术，通过给模型提供一小部分示例，帮助它理解如何执行特定的任务。在链式思维的上下文中：

     * **包含链式思维序列的示例**：在进行少量示例提示时，开发者可以将一些具体的链式思维序列作为示例添加到提示中。这些示例展示了如何通过一系列推理步骤得出结论。
     * **模型学习模仿**：通过这些示例，模型能够学习如何在遇到类似问题时，模仿这种逐步推理的方式。模型会试图根据提供的示例来生成自己的推理链。

     :pager:示例说明

     假设我们有一个模型需要解决问题：“一个人在商店里买了5个面包，每个面包的价格是3元。他总共花了多少钱？”我们可以提供如下示例：

     1. **示例1**：
        * 输入：一个人买了5个面包，每个面包3元，他总共花了多少钱？
        * 输出：5个面包的价格是3元 × 5 = 15元。
     2. **示例2**：
        * 输入：如果每个苹果的价格是2元，买3个苹果需要多少钱？
        * 输出：2元 × 3 = 6元。

     在给模型提供这些示例后，<u>模型会学会如何将类似问题分解为中间推理步骤</u>，并最终得出正确的答案。

### 外部知识增强技术

:musical_keyboard:当仅依赖LLM的参数和内部知识不足以回答问题时，开始引入外部数据来增强模型能力。

#### 检索增强生成：retrieval-augmented generation(RAG)

定义：large language models with external knowledge bases have been developed. These are used to produce more accurate and contextually relevant text responses. This approach is called **Retrieval-Augmented Generation**

使用：这种迭代方法使用模型的输出作为上下文，根据这个上下文去获取与这个上下文提及的内容有关的信息（知识），那么，随着新的相关知识的引入，模型在进行下一次迭代时，就有了更丰富的信息基础，会产生更好的结果。

> [!CAUTION] 
>
> 大型语言模型通常需要纳入{现有训练数据集}**未涵盖**的用户特定数据。检索增强生成是一项关键技术，它通过检索外部数据并将其纳入生成过程，有助于提高语言模型回复的准确性和相关性。

:sailboat:主要流程

1. **查询向量化**：首先，用户的查询（query）会被转化成向量。
2. **向量检索**：将查询的向量发送到**向量数据库**，通过向量相似度来找到和查询向量最相似的文档向量。向量数据库根据相似度返回一组相关文档。
3. **文档生成**：检索到的相关文档作为生成模型的输入，生成模型（如 GPT-3）会利用这些文档来生成答案或进一步的文本。

:label:==改进RAG==：`reranker`

在信息检索（information retrieval）系统中，通常分为两个步骤：

* 初步检索：使用像BM25、TF-IDF或基于向量的检索方法来快速生成与用户查询相关的一批候选文档。这个过程返回一组初步的候选结果，通常可以是数百甚至数千个文档。

* **Reranking（重排序）**：这些初步结果中的相关性可能不够精准或排序不理想，因此我们使用 **reranker** 来对这些候选结果进行更细致的分析，重新排列它们的顺序，使最相关的文档排在最前面。

  > Reranking（重排序）通常通过更深度的模型（例如 Transformer 架构）来对每个候选文档和用户查询进行交互建模。这种做法比初步检索器更精准，因为它能进行更深入的语义分析。

  :sailboat:以BERT-based Reranker为例：

  初步检索：获得候选文档

  BERT-based reranker 通过对用户的查询和每个候选文档进行**更细粒度的语义匹配**，来重新评估每篇文档的相关性。

  1. 文本表示：对查询和文档进行编码。查询和文档并不是独立处理的，而是会放在一起做更深度的交互建模。

  2. 构造输入格式

     对于每个候选文档，BERT reranker 会将**用户的查询和文档拼接在一起**，形成一个新的输入格式。比如，对于文档 1：

     ```python
     输入格式： "[CLS] 最好的手机是什么？ [SEP] iPhone 的评论内容... [SEP]"
     [CLS]：这是 BERT 用来生成全局表示的特殊 token，它会捕捉整个输入的语义。
     [SEP]：用于区分查询和文档内容。
     ```

  3. 交互建模：查询和文档的深度匹配。

     BERT 的自注意力机制会对<u>查询中的每个词</u>与<u>文档中的每个词</u>进行交互建模，从而更好地理解二者的语义匹配度。

     这一步让模型不仅能够理解查询和文档中单词的匹配，还能捕捉更复杂的语义信息和上下文依赖关系。

  4. 得分计算

     经过 BERT 的多层 Transformer 处理后，模型会输出一个代表该对查询-文档的相关性得分。通常，BERT 会使用输出的 `[CLS]` 向量表示整个输入的语义，并通过一个简单的线性层将其转化为一个**相关性分数**。

  5. 重新排序，返回重排序结果

#### AI Agentic Workflow

agentic workflow是一种与LLM交互和完成任务的新方法，它通过将复杂任务分解为多个子任务，并引导LLM逐步完成每个子任务来实现。这种方法不是一次性地向LLM提出一个复杂指令，而是借助AI开发平台将任务分解成多个步骤，在不同环节进行迭代，指导最终生成期望的结果。

Agentic Workflow的实现通常依赖于模块化设计，其中每个模块或组件负责特定的任务或功能。这种设计允许灵活地添加、更新或替换模块，以适应不断变化的业务需求和技术进步。在Agentic Workflow中，AI Agent形成一个网络，每个Agent拥有自己的专长和责任。通过网络协作，它们能够共同处理复杂的任务，实现比单个Agent更高效的工作流程

此外，Agentic Workflow还包括一个自适应循环，其中AI Agent不断收集反馈，评估性能，并根据反馈调整自己的行为，确保了工作流的持续优化和改进。为了与人类用户和其他系统集成，Agentic Workflow提供了交互式界面，支持自然语言交互和可视化操作，提高了用户体验和系统的可访问性

:sailboat:区分AI Agent和Agentic Workflow

* AI Agent侧重于单个智能体的能力和自主性，它们可以独立执行任务或作为更大系统中的一部分。例如，大语言模型可以作为一个AI Agent，它根据你的问题生成合适的回答。
* Agentic Workflow则侧重于多个AI Agent如何组织和协作来完成复杂的任务，它是一种工作流程的设计方法，强调任务分解、迭代优化和模块化。

### 总结

| Zero-shot Learning和Prompt Engineering                       | RAG                                                          | Agentic Workflow 和 Reasoning RAG                            |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 随着LLM的规模越来越大，模型掌握了足够广泛的语言和知识模式，通过巧妙设计提示词，模型在很多下游任务中不需要额外训练也可以取得不错的效果。 | 随着任务的复杂化，LLM所掌握的知识可能不足以应对所有任务（尤其是涉及到最新信息或特定领域的任务）。因此，结合外部检索系统，弥补模型知识的不足。 | 当任务变得更加复杂，模型不仅需要生成答案，还要有能力自主规划、执行和调整策略。Agentic Workflow 正是应对这些复杂任务需求的一种技术，通过将模型的生成能力与工作流管理系统结合 |
| 适用于模型需要高效完成未见过的任务                           | 尤其适合需要实时获取最新信息或外部知识的场景，如特定私有产品、技术支持等。 | 特别适合多任务处理、自动化任务执行的场景，例如多步骤问答系统、自动化执行工作流等。 |
| 得益于 **GPT-3** 这样的超大规模模型的出现，模型拥有强大的泛化能力和上下文理解能力，从而催生了Prompt Engineering的蓬勃发展。 | RAG技术出现在解决模型知识盲点和更新滞后的需求下，尤其是像 **GPT-3** 这样的模型，其预训练数据可能过时，而外部检索可以弥补这一缺陷。 | 随着 **自动化任务** 和 **复杂推理任务** 的需求增加，这些技术得到了进一步发展，结合RAG的推理增强也是为了应对复杂任务推理需求的提升。 |

`共通点`：所有这些技术都是基于LLM的预训练能力，它们都没有改变模型的权重，只是通过优化输入（提示词）或引入外部知识/自动化任务管理来改进模型的表现。关系：Prompt Engineering 更关注如何通过优化提示词提升模型性能，而 RAG 则引入了外部知识增强。Agentic Workflow 则是对复杂任务管理和自动化执行的扩展。

## 需要train的LLM改进

大型语言模型在许多应用中都需要纳入用户的特定数据，而这些数据并不在模型原有的训练数据集中。为了给用户生成更准确且与上下文相关的回复，需要检索外部数据，并在生成回答时将其纳入LLM。

### 全参微调技术

#### 下游任务微调

一般说的微调就是指：用下游任务数据微调

预训练模型已经在大规模数据集上学到了通用的知识（通用特征），在你使用它来处理下游任务时，你会将下游任务的数据用来进一步训练模型。这个过程的核心目标是让模型在下游任务上表现得更好。

> [!CAUTION]
>
> 在这个过程中，模型的所有参数都可能被更新，所以这种方法适用于当下游任务和预训练任务有较大差异的时候，更关注模型能否在具体任务上给出正确的结果。

**应用场景：** 比如，将BERT预训练模型用于情感分类等。

#### 指令微调

| 训练集                                                       | 指令数据                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 这是指模型在预训练过程中使用的所有数据。通常是从互联网、大型文本语料库中收集的，数据内容可能包括各种类型的文章、对话、代码、书籍等。 | **指令数据**则是在模型已有语言能力基础上，让它学习“如何执行任务”和“如何跟随指令”。这是在模型掌握基础语言知识后，通过微调模型（fine-tuning），提升它的具体任务执行能力。 |
| 这些数据可以帮助模型学习语言结构、上下文理解、常识知识等，主要是让模型“理解语言”和“掌握知识”。 | 这些指令数据通常会有明确的输入（比如问题或指令）和期望的输出（比如回答、执行步骤），重点是让模型学会“如何按照指令执行任务”。 |
|                                                              | 指令：翻译成另一种语言；给出这个句子的总结；给定以下段落，总结出主要内容。 |

**用指令数据（instruction data）在预训练模型**的基础上进行进一步调整和优化。

**预训练（Pre-training）**：

* 模型最初通过海量的训练集数据（包括各种文本）进行预训练。这个阶段的目的是让模型学习语言的基本结构、语法、上下文关系以及常识性知识。这个过程通常使用自监督学习，即模型通过预测词汇或句子来进行训练，学习如何理解和生成文本。

**微调（Fine-tuning）**：

* 微调是在预训练模型的基础上，使用更为专门的数据进行训练。在这里，指令数据扮演了关键角色。通过微调，模型不仅仅是理解语言，还需要学会如何“按照指令行事”，即它需要根据给定的任务指令（如回答问题、翻译、总结等）生成符合要求的输出。
* 微调过程就是用指令数据对模型进行“定向优化”，提升它对指令的理解和执行能力。

:radio_button:举个例子：

假设你有一个已经预训练好的模型，它可以回答各种各样的问题。如果你想让它更加准确、有效地回答特定领域的问题（比如医疗领域），你就可以用特定领域的指令数据（如“给定症状，提供诊断建议”）来对模型进行微调。

:black_joker:常见做法：

微调过程中是否**只使用指令数据**还是需要**其他训练数据**，取决于具体的任务和模型的需求。通常情况下，微调过程中主要**使用指令数据**。

* **主要目标**：微调的主要目的是让模型在已有的基础上，学会根据特定任务或指令更好地执行操作。所以，在大部分情况下，微调过程中**只使用指令数据**进行训练就可以了。指令数据包含任务的输入和期望输出，通过这些数据可以让模型专注于学会如何根据指令提供正确的回应。
* **例子**：比如你想让模型学会回答问题、翻译文本或总结段落，只要有足够的指令数据（包括问题-答案、输入-输出对），在微调过程中模型就能逐渐学会如何根据指令产生相应的结果。

:o:引申出 instruction-tuned models: 指在预训练的大模型基础上，使用特定的**指令数据（instruction data）**进行微调得到的模型。

简单来说，预训练的大语言模型（像GPT等）是在大量通用数据上进行训练的，它们学会了广泛的语言知识，但没有特定地学会如何遵循某些任务或指令。而**指令微调（instruction tuning）是进一步使用专门设计的指令数据集**，让模型学会按照人类的要求来处理特定任务。这些数据集通常包含任务指令和相应的期望输出，帮助模型更好地理解和执行类似“回答问题”、“生成代码”等具体任务。

通过这种微调，模型变得更加擅长处理“指令式”任务，用户可以通过给定明确的指令来让模型完成指定的任务，比如你现在的提问。

```python
你是一个大语言模型方向上的专家，请你帮助我理解下面这篇论文的摘要。
```

### 参数高效微调技术

* `LoRA`：LoRa 通过引入一些低秩矩阵来减少需要更新的参数量。在具体操作时，它会在原有模型的权重矩阵上叠加一些低秩矩阵，从而在微调时只更新这些低秩矩阵的参数，而保持预训练模型的大部分权重不变。

  > [!CAUTION]
  >
  > lora比较适应模型比较大的情况下。如果你的模型本身比较小/用于微调的数据本身比较小，建议选择用冻结部分参数进行微调。

* `Adapter`：在原始大模型的各层中插入一些**小型的可学习模块（适配器层）**，并且**仅仅微调这些适配器层的参数**，而不会调整模型的其他部分。模型的原始权重会被**冻结（freeze）**，这样能有效地保留大模型已经学到的通用知识，而通过适配器层来让模型适应新的任务。

  :name_badge:工作流程：

  1. **插入adapter模块**：我们在神经网络的某些层（通常是Transformer的每层或者特定的几层）中引入一个小型的瓶颈网络。这个瓶颈网络通常由两部分组成：这个瓶颈结构可以是一个较小的全连接层，输入是原层的输出，经过一些学习后的变换再输出。这样通过瓶颈部分减少计算量。
  2. **冻结原有模型参数**：模型的原始权重保持不变，adapter模块会学习到对特定任务有用的特征。
  3. **参数量小，效果佳**：adapter模块的参数量很小，通常只占原模型的不到1%。由于只需要训练adapter的参数，因此相比微调整个模型，训练的成本大大降低。
  4. **效果**：尽管adapter的参数量很少，但在许多自然语言处理任务中，它的性能与全量微调整个模型的效果非常接近。

  优点：

  1. **模块化**：适配器可以针对不同的任务进行特定的训练，并且在后续的任务中可以灵活加载不同任务的适配器层，而不需要重复微调整个模型。

     适配器的具体位置管理是透明的，你只需专注于添加和激活它们，而不需要手动调整模型的架构。

     ```python
     from transformers import BertModel, AdapterConfig
     
     # 加载预训练模型
     model = BertModel.from_pretrained("bert-base-uncased")
     
     # 添加适配器
     model.add_adapter("taskA_adapter")  # 添加任务A的适配器，位置由库自动处理
     
     # 激活适配器
     model.set_active_adapters("taskA_adapter")
     ```

  2. **参数独立性**：适合需要频繁切换任务的场景，只需保存这些Adapter参数。

### 总结：

* **更新参数量**：从 **全量更新**（如直接微调、指令微调）到 **小量更新**（如LoRa、Adapter），再到 **极少更新**（如Prompt-tuning），参数更新量逐渐减少。
* **应用场景**：如果你的任务跟预训练差异较大，建议全量微调；而如果模型需要频繁切换任务或者资源有限，LoRa和Adapter是更好的选择。
* **优缺点权衡**：全参数微调效果更好但开销大，低参数微调（如LoRa、Adapter）更高效，但在一些复杂任务上性能可能稍逊。

## LLM创新方法(来自papers)

### RAFT: 在指令微调的过程中加入RAG

:label:user's prompt

> 在使用大模型模型LLM时，用户会给出一个提示，也就是问题或任务说明，这个提示就是所谓的‘prompt’
>
> users' prompt可以理解为：
>
> * 明确任务：帮助模型理解用户的需求，确定要执行的具体任务。例如，如果你给出一个问题作为 prompt，模型就会尝试回答这个问题。
> * 引导输出风格：可以影响模型生成文本的风格、语气、格式等。比如，要求模型以诗歌的形式回答，或者以正式的商务语言回复。
> * 提供背景信息：有时，prompt 中可以包含一些背景信息，让模型在特定的情境下进行回答。这有助于提高回答的准确性和相关性。

`Closed-Book Exam`: LLM在答题过程中无法获得任何其他文件或参考资料的情况

`Open Book Exam`: 将开卷考试比作LLM可以参考外部信息源（外接知识库）的情景。LLM会与一个检索器（retriever）结合使用。这个检索器的作用就是从大量的文档或知识库中检索出与用户问题相关的信息。

`Domain-Specific Open-Book Exam`: 我们预先知道 LLM 将在哪个领域接受测试。具体领域的例子包括企业文件、属于某个组织的代码库等。在所有这些场景中，LLM 都将用于回答问题，而问题的答案可以在文档集合中找到。RAFT<u>更加强调模型的阅读理解能力，而不仅仅是对检索结果的依赖。通过在训练时引入正向文档和干扰文档，模型能在特定领域中表现得更加准确和鲁棒</u>。

| RAG                                                          | RAFT                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 在大多数情况下并不需要额外的训练，因为它主要依赖于现有的检索器来找到相关文档，然后让模型直接从这些文档中生成回答。换句话说，RAG的重点在于通过检索相关文档，模型结合这些检索结果进行推理或生成答案。 | 需要额外的训练，因为它强调的是如何让模型从正向文档和干扰文档中学习，并且提高模型在面对混合信息时的鲁棒性。因此，RAFT不仅仅是依赖检索的结果，而是通过训练，专门适应特定领域，并学会在有干扰信息的情况下更好地做出判断。这就需要模型通过专门的微调（fine-tuning）来提升其能力。 |

### MetaGPT：LLM的多智能体系

:notebook_with_decorative_cover:SOP：通过广泛的协作实践，人类已经在各个领域形成了广为接受的标准化操作程序（SOP），这些SOP在支持任务分解和有效协调方面发挥着至关重要的作用。此外，SOP还概括了每个团队成员的职责，同时建立了中间产出的标准。

:shamrock:MetaGPT为什么要引入人类实践操作到多智能系统中

已有研究：以前的研究更像是在模拟<u>一个开放世界里的人类行为</u>，就像一个虚拟的游戏世界，智能体（AI）要学习如何在这个世界里表现得像人类。这种情况下，智能体的任务是**随意的**，像探索和互动，不一定有明确的目标或流程。

MetaGPT：它的目标是让智能体学习**人类的工作方式**，特别是那些<u>有固定步骤的工作流程</u>。比如在软件开发中，我们有很多标准化的流程、规则、以及分工合作方式。把这些广为接受的人类工作经验(SOP)整合到智能体之间的协作中，让它们像人类一样合理地分工、合作、并有条理地完成复杂任务。

简单说：

* 以前：智能体像在模拟一个开放的虚拟世界里，干各种各样的事情，没有固定的操作方法。
* MetaGPT：智能体像学习人类怎么一起工作，有明确步骤和分工，合作更高效。

:label:主要工作：

1. MetaGPT专门用于基于大语言模型（LLM）的多智能体协作，这种框架具备高度的**便利性和灵活性**，其中包括几个清晰定义的功能：
   * **角色定义**：不同的智能体在协作中扮演不同的角色。
   * **消息共享**：智能体之间可以进行有效的消息传递和共享。
2. MetaGPT在设计中**创新性地整合了人类的标准操作程序（SOPs）**，这使得系统的**鲁棒性**（即系统应对不确定性和错误的能力）得到了显著提升，避免了智能体之间无效或低效的合作。另外，他们还引入了一种**新的执行反馈机制**，能够在运行时调试和执行代码。

:handbag:具体地：MetaGPT如何通过角色分工和SOPs来优化智能体的合作。

1. **角色分工的专业化：** **角色的明确分工**可以帮助把复杂任务拆解成更小、更具体的任务。不同的智能体（agents）各自具备不同的技能和专长，这样可以让他们各司其职，协作完成复杂的问题。

2. **MetaGPT中的角色设定：** 在MetaGPT中，定义了五个主要角色：**产品经理**、**架构师**、**项目经理**、**工程师**和**QA工程师**。每个角色都有具体的属性，比如名字、目标、约束条件等，还定义了该角色特有的技能。

3. **智能体的行为模式：** 工作流中的**智能体像是时刻“倾听”外界信息的工作人员**。他们会关注周围的环境，这里的环境具体来说就是**消息池**中的信息。每当有新的消息出现时，这些智能体会做出反应，可能是立刻采取行动，或者利用这些信息来帮助完成他们的任务。

4. **工作流程：** 通过定义角色和技能，MetaGPT可以为智能体建立**基础工作流程**。这些流程是基于软件开发中的SOP来设计的，确保智能体可以按照顺序完成任务。

   * 具体来说，流程开始于获取用户需求，然后**产品经理**进行分析，写出**PRD**（产品需求文档），其中包括用户故事和需求池，进行初步的功能拆分。
   * 接着，**架构师**会将需求转化为系统设计，比如文件列表、数据结构、接口定义等。
   * 然后，这些设计交给**项目经理**，负责分配任务。
   * **工程师**再根据分配的任务编写代码和函数。
   * 最后，**QA工程师**会制定测试用例，确保代码质量。

   这个流程一步步执行，最终由MetaGPT生成一个**精心制作的软件解决方案**。

### MOELoRA：参数高效微调框架













